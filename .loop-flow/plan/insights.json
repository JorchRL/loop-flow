{
  "schema_version": "0.1.0",
  "description": "Structured learnings (zettelkasten). Links form a knowledge graph.",
  "insights": [
    {
      "id": "INS-001",
      "content": "Learnings have a hierarchy of leverage: process > domain > architecture > edge_case > technical. Higher-leverage learnings compound more over time.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1"
      },
      "tags": ["meta", "knowledge-management"],
      "links": [],
      "created": "2026-01-17"
    },
    {
      "id": "INS-002",
      "content": "Loop-Flow is not just a workflow tool — it's a theory preservation system (ref: Naur's 'Programming as Theory Building'). The code is the artifact, but the theory in your head is the real product.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1"
      },
      "tags": ["vision", "philosophy"],
      "links": ["INS-001"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-003",
      "content": "The relationship between two insights is often an insight itself. Links in the knowledge graph are first-class, not just pointers.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1"
      },
      "tags": ["knowledge-management", "zettelkasten"],
      "links": ["INS-001"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-004",
      "content": "Insights need two modes: quick capture (snapshot without derailing work) and deep synthesis (dedicated discussion time). This mirrors inbox vs focused work.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1"
      },
      "tags": ["workflow", "context-management"],
      "links": ["INS-001", "INS-003"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-005",
      "content": "Knowledge compounds through abstraction: many concrete insights synthesize into fewer abstract principles. This is how context stays bounded while wisdom grows.",
      "type": "process",
      "status": "unprocessed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1"
      },
      "tags": ["scaling", "knowledge-management", "future"],
      "links": ["INS-001", "INS-003"],
      "created": "2026-01-17",
      "notes": "Deferred for deeper exploration when we hit the scaling problem."
    },
    {
      "id": "INS-006",
      "content": "Task selection is collaborative: agent proposes based on priority/dependencies, human decides based on current state, mood, emergent needs. The backlog is a menu, not a queue.",
      "type": "domain",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1"
      },
      "tags": ["workflow", "task-management"],
      "links": [],
      "created": "2026-01-17"
    },
    {
      "id": "INS-007",
      "content": "Context window is a resource you actively manage. Session endings are triggered by: task complete, natural stopping point, or approaching compaction — not just 'done'.",
      "type": "domain",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1"
      },
      "tags": ["workflow", "context-management"],
      "links": ["INS-004"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-008",
      "content": "The agent is the user's external memory. User walks in cold, agent reminds THEM. Flip the traditional 'user provides context' model.",
      "type": "domain",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1b"
      },
      "tags": ["ux", "cold-start"],
      "links": ["INS-002"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-009",
      "content": "Trust by default, friction on request. Autosave everything, then show summary. User can tweak after, not before. Protects against session death.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1b"
      },
      "tags": ["ux", "session-end", "trust"],
      "links": ["INS-007"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-010",
      "content": "Conversation has modes: Work, Discovery, Discuss, Review. Modes are descriptive (agent reads the vibe), not prescriptive (no rigid state machine). They blend fluidly.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1b"
      },
      "tags": ["ux", "modes", "conversation"],
      "links": ["INS-004"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-011",
      "content": "Discovery mode is distinct from Discuss. Discovery = rapid Q&A to extract requirements (breadth). Discuss = Socratic deep-dive on one insight (depth). Both are valuable, different purposes.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1b"
      },
      "tags": ["ux", "modes", "discovery"],
      "links": ["INS-010", "INS-004"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-012",
      "content": "Interactive pickers (TUI questions) are better than prose for choices. One line of context, then picker. Keeps context tight, makes decisions fast.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1b"
      },
      "tags": ["ux", "interaction", "context-efficiency"],
      "links": ["INS-007", "INS-011"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-013",
      "content": "In Work mode, avoid meta-commentary — preserve context budget. In other modes (Discovery, Discuss), naming the mode shift can help orient the conversation.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.5",
        "session": "2026-01-17-S1b"
      },
      "tags": ["ux", "modes", "context-management"],
      "links": ["INS-010", "INS-007"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-014",
      "content": "Terseness in bootstrap/scaffolding files is a form of pre-emptive context rot. You're compacting knowledge before it even reaches the new project. Bootstrap files are used once per project — length doesn't matter, completeness does. Optimize for full knowledge transfer, not brevity.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.6",
        "session": "2026-01-17-S2"
      },
      "tags": ["bootstrap", "context-rot", "knowledge-transfer"],
      "links": ["INS-007", "INS-005"],
      "created": "2026-01-17"
    },
    {
      "id": "INS-015",
      "content": "Loop-Flow's secondary goal is fostering learning and growth toward becoming a great software engineer. This contrasts with 'vibe coding' where AI does the thinking. AI is powerful but dangerous to our capacity for deep thought — a fundamental pillar of being human. Loop-Flow uses AI to amplify human thinking, not replace it. The 'developer has the reins' principle isn't just about control; it's about preserving and developing the capacity to think deeply about software.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001.6",
        "session": "2026-01-17-S2"
      },
      "tags": ["philosophy", "learning", "growth", "cognition", "anti-vibe-coding"],
      "links": ["INS-002"],
      "created": "2026-01-17",
      "notes": "From Jorge's cognitive science background. AI should be a tool that makes us better thinkers, not a crutch that atrophies our thinking."
    },
    {
      "id": "INS-016",
      "content": "When teaching domain concepts, provide probing questions alongside the explanation. Questions guide active reading and help the learner build their own mental model rather than passively absorbing information.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["teaching", "learning", "ai-agent-patterns", "loop-flow-domain"],
      "links": ["INS-015", "INS-011"],
      "created": "2026-01-18",
      "notes": "Discovered while teaching MCP concepts. Connects to the broader Loop-Flow philosophy of fostering growth (INS-015) and the Discovery mode pattern of guided exploration (INS-011)."
    },
    {
      "id": "INS-017",
      "content": "Loop-Flow architecture is local-first. Local SQLite is source of truth. Team/cloud features layer on top via sync, not the other way around. This preserves developer autonomy, enables offline work, and keeps the MVP simple. Remote-first would create service dependency that contradicts 'developer has the reins'.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["architecture", "local-first", "design-decision"],
      "links": ["INS-015", "INS-002"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-018",
      "content": "Loop-Flow evolves in four phases: Phase 0 (file-based bootstrap — current workflow bootstraps the MCP implementation), Phase 1 (local MCP + SQLite — MVP), Phase 2 (local web dashboard via HTTP API), Phase 3 (optional SaaS with cloud sync for teams). Each phase is self-contained and valuable. The MCP server can grow an HTTP API without changing the MCP interface — clean separation of concerns.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["architecture", "roadmap", "phases", "dogfooding"],
      "links": ["INS-017", "INS-002"],
      "created": "2026-01-18",
      "notes": "Phase 0 is key: Loop-Flow uses its own file-based workflow to build itself. True dogfooding."
    },
    {
      "id": "INS-019",
      "content": "AI should proactively probe for emerging insights during conversation. When an idea starts floating around but isn't yet articulated, steer toward surfacing it. Don't wait for the user to explicitly say 'let's capture this' — notice the nascent insight and help bring it into focus. This is active theory extraction, not passive note-taking.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["ai-agent-patterns", "insight-capture", "proactive", "theory-building"],
      "links": ["INS-015", "INS-016", "INS-004"],
      "created": "2026-01-18",
      "notes": "Meta-insight: this insight itself was surfaced by the user noticing the agent wasn't doing this proactively enough. The agent should have noticed the pattern emerging (INS-016 + INS-015) and proposed this synthesis."
    },
    {
      "id": "INS-020",
      "content": "Periodic insight review sessions ([REVIEW] tasks) could be valuable: browse accumulated insights, find new connections, synthesize higher-level principles. This is gardening the knowledge graph, not just adding to it.",
      "type": "process",
      "status": "unprocessed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["insight-capture", "knowledge-management", "review", "synthesis"],
      "links": ["INS-003", "INS-005"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-021",
      "content": "Loop-Flow could proactively seek llm.txt or similar machine-readable domain knowledge hooks when entering a new domain. These files are designed to give LLMs efficient context about a project/technology. During learning and discovery phases, the agent could look for these to accelerate understanding.",
      "type": "domain",
      "status": "unprocessed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["learning", "discovery", "context-efficiency", "llm-txt", "future-feature"],
      "links": ["INS-016", "INS-019"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-022",
      "content": "MCP distinguishes Tools (model-controlled actions) from Resources (application-controlled context). Tools are for doing things (task.add, loop.end). Resources are for providing data (loopflow://learnings/recent). Resources let the host decide WHEN to fetch context, which helps manage context pollution. Loop-Flow should use both: Tools for actions, Resources for context that the host can selectively load.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["mcp", "architecture", "tools", "resources", "context-management"],
      "links": ["INS-017", "INS-007"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-023",
      "content": "Loop-Flow should maintain a domain knowledge index — a database of links to external docs, references, and context sources. Designed like llms.txt: an index with links that agents can 'glance' at without loading everything. The agent sees what's available, then fetches only what's needed. This is 'lazy loading' for context. A subagent could read the index and decide what to expose to the main agent, acting as a context curator.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["architecture", "context-management", "domain-knowledge", "lazy-loading", "subagent"],
      "links": ["INS-021", "INS-022", "INS-007", "INS-005"],
      "created": "2026-01-18",
      "notes": "Inspired by llms.txt pattern. Connects to context scaling (INS-005) and the MCP Resources primitive (INS-022). The subagent-as-curator idea is powerful — separates 'what exists' from 'what's relevant now'."
    },
    {
      "id": "INS-024",
      "content": "Two-tier context curation: Tier 1 uses embeddings/vector similarity for fast recall (narrow 1000s to 10s). Tier 2 uses LLM judgment for precise selection (narrow 10s to the right 2-3). Embeddings are cheap and fast but lack reasoning. LLMs are expensive but apply judgment. Combine them: vector search surfaces candidates, LLM curator picks winners. Main agent's context stays clean.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["architecture", "context-management", "embeddings", "curation", "two-tier"],
      "links": ["INS-023", "INS-022", "INS-005"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-025",
      "content": "Learning and discovery are not sequential phases — they blend together in a generative loop. The agent's input prompts the human to think deeper about the domain, which surfaces new insights, which the agent helps articulate, which prompts further thinking. This co-creative dialogue is a key aspect of Loop-Flow. The agent isn't just extracting knowledge — it's catalyzing knowledge creation.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["process", "learning", "discovery", "co-creation", "dialogue", "loop-flow-philosophy"],
      "links": ["INS-019", "INS-016", "INS-015", "INS-011"],
      "created": "2026-01-18",
      "notes": "High-leverage process insight. This is what makes Loop-Flow different from a passive note-taking system. The agent is an active thinking partner."
    },
    {
      "id": "INS-026",
      "content": "Modes are internal vibes the agent spontaneously takes based on context. Tasks are explicit activities requested by the user or proposed by the agent. Modes are fluid and blend; tasks are discrete and trackable. The agent doesn't announce mode switches — it reads the room and adapts.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["process", "modes", "tasks", "loop-flow-philosophy"],
      "links": ["INS-010", "INS-011", "INS-025"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-027",
      "content": "Learn mode: acquiring external knowledge and grounding it in the project's context. Has a grounding topic (docs, library, domain) that we orbit around. Divergences happen when something sparks — agent notices and gently grounds back. Produces: understanding, insights, AND design refinements. Distinct from Discovery (focused requirements extraction) and Discuss (philosophical back-and-forth on insights). Learn mode blends teaching, questioning, and synthesizing.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-18-S3"
      },
      "tags": ["process", "modes", "learning", "loop-flow-philosophy"],
      "links": ["INS-025", "INS-026", "INS-011", "INS-016"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-028",
      "content": "Bootstrap/setup files should be unified and versioned. A single file that auto-detects whether to install fresh or update existing reduces confusion and ensures all installations can be brought to the same version. Version at top for quick reference, full changelog for details. Process insights tagged with 'loop-flow-core' carry methodology forward between versions.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-020",
        "session": "2026-01-18-S4"
      },
      "tags": ["loop-flow-core", "distribution", "versioning", "process"],
      "links": ["INS-014"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-029",
      "content": "Skills are reusable agent capabilities that encode specific knowledge about how to perform a task. Two types emerge: (1) Loop-Flow Core Skills — ship with Loop-Flow, available in any project (e.g., /version, /session-start, /session-end), and (2) User-Defined Skills — repo-specific, defined per project for its unique needs (e.g., /deploy, /release-notes). Skills bridge the gap between generic agent capability and project-specific knowledge.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-021",
        "session": "2026-01-18-S5"
      },
      "tags": ["skills", "architecture", "extensibility", "loop-flow-core"],
      "links": ["INS-028", "INS-002"],
      "created": "2026-01-18",
      "notes": "Discovered while doing version bump for LF-021. The repetitive multi-file update pattern suggested a skill. Skills are like 'macros with knowledge' — they know what to do AND where things are."
    },
    {
      "id": "INS-030",
      "content": "Versioning should have a single source of truth (VERSION_MANIFEST) that lists: current version, changelog, and all locations where version appears. The /version skill reads this manifest, updates it with new changelog entry, then propagates to all referenced files, regenerates distribution files if needed, and verifies consistency. Human triggers version bumps at meaningful milestones, not every commit.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-021",
        "session": "2026-01-18-S5"
      },
      "tags": ["versioning", "skills", "process", "loop-flow-core"],
      "links": ["INS-029", "INS-028"],
      "created": "2026-01-18"
    },
    {
      "id": "INS-031",
      "content": "Loop-Flow needs cross-project insight flow. When working in Project A, insights about Project B should be capturable and 'exportable'. Tags like 'export-to:loop-flow' could mark insights for cross-pollination. For now, a separate file (insights-to-export-to-loop-flow-main.json) serves as a staging area.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "LF-023",
        "session": "imported from learn-tdd-go",
        "original_id": "EXPORT-001"
      },
      "tags": ["loop-flow-core", "insight-capture", "cross-project"],
      "links": [],
      "created": "2026-01-20"
    },
    {
      "id": "INS-032",
      "content": "LoopFlow needs encapsulated commands/skills for common tasks. Example: 'loop start' command that reliably reads .loop-flow/ state (glob often fails to find the folder, requiring manual 'ls' instructions). Skills should be simple invocations that 'just work' without the user having to remember the right incantations.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "LF-023",
        "session": "imported from learn-tdd-go",
        "original_id": "EXPORT-002"
      },
      "tags": ["loop-flow-core", "skills", "ux", "reliability"],
      "links": ["INS-029", "INS-030"],
      "created": "2026-01-20",
      "notes": "Concrete use case for skills: /start-session skill that 'just works'."
    },
    {
      "id": "INS-033",
      "content": "Loop-Flow based learning is effective because: (1) Chat with AI is engaging for ADHD brains — immediate feedback loop, (2) Text-based interaction forces writing, which forces thinking (ref: Zinsser's 'Writing to Learn'). Loop-Flow could be a platform for interactive courses, not just development workflow.",
      "type": "process",
      "status": "unprocessed",
      "source": {
        "task": "LF-023",
        "session": "imported from learn-tdd-go",
        "original_id": "EXPORT-003"
      },
      "tags": ["loop-flow-core", "learning", "courses", "adhd", "writing-to-learn"],
      "links": ["INS-015", "INS-025"],
      "created": "2026-01-20"
    },
    {
      "id": "INS-034",
      "content": "Verification functions as a testing pattern: Write pure functions that take algorithm output and return true/false + diagnostic data. These verification functions (1) encode the rules/constraints, (2) can be unit tested independently, (3) enable 'vibecoding' the algorithm implementation safely, (4) can be reused in production for debugging tools. This separates 'what is correct' from 'how to compute it'.",
      "type": "domain",
      "status": "unprocessed",
      "source": {
        "task": "LF-023",
        "session": "imported from learn-tdd-go",
        "original_id": "EXPORT-004"
      },
      "tags": ["testing", "verification-functions", "pure-functions", "vibecoding"],
      "links": [],
      "created": "2026-01-20",
      "notes": "Concrete testing pattern that should inform Loop-Flow's testing philosophy. Also a spec-driven-development pattern."
    },
    {
      "id": "INS-035",
      "content": "Spec-driven development: Tests encode the specification. The spec is the source of truth, not the implementation. AI can 'vibecode' the implementation because the spec (tests + verification functions) catches violations. This inverts the traditional 'code then test' flow and makes AI-assisted development safer.",
      "type": "process",
      "status": "unprocessed",
      "source": {
        "task": "LF-023",
        "session": "imported from learn-tdd-go",
        "original_id": "EXPORT-005"
      },
      "tags": ["testing", "spec-driven", "tdd", "ai-assisted", "loop-flow-core"],
      "links": ["INS-034", "INS-015"],
      "created": "2026-01-20",
      "notes": "Connects to Loop-Flow's 'developer has the reins' principle. Human writes spec, AI implements. Spec is the control mechanism."
    },
    {
      "id": "INS-036",
      "content": "The human's job in AI-assisted development is to write specs that capture what actually matters. The implementation is a consequence of the spec. Expertise lies in knowing what to specify — this is the hard part that AI cannot do.",
      "type": "process",
      "status": "unprocessed",
      "source": {
        "task": "LF-023",
        "session": "imported from learn-tdd-go",
        "original_id": "EXPORT-006"
      },
      "tags": ["testing", "spec-driven", "ai-assisted", "expertise", "philosophy", "loop-flow-core"],
      "links": ["INS-035", "INS-034", "INS-015"],
      "created": "2026-01-20",
      "notes": "Defines the human role in Loop-Flow: spec author, not implementer."
    },
    {
      "id": "INS-037",
      "content": "When the problem is constraint satisfaction (many valid outputs exist), verification functions + property-based testing is more valuable than example-based unit tests. Example tests prove 'this specific case works', property tests prove 'this always works for any valid input'.",
      "type": "domain",
      "status": "unprocessed",
      "source": {
        "task": "LF-023",
        "session": "imported from learn-tdd-go",
        "original_id": "EXPORT-007"
      },
      "tags": ["testing", "property-based-testing", "verification-functions", "patterns"],
      "links": ["INS-034"],
      "created": "2026-01-20",
      "notes": "Informs when to use property-based vs example-based testing."
    },
    {
      "id": "INS-038",
      "content": "Verification functions can serve double duty: (1) test oracles during development, (2) runtime debugging tools in production. The same constraint-checking logic that validates tests can power user-facing diagnostic features. Tests and features share infrastructure.",
      "type": "domain",
      "status": "unprocessed",
      "source": {
        "task": "LF-023",
        "session": "imported from learn-tdd-go",
        "original_id": "EXPORT-008"
      },
      "tags": ["testing", "verification-functions", "production", "debugging", "reuse"],
      "links": ["INS-034"],
      "created": "2026-01-20",
      "notes": "Testing code isn't throwaway — it can be production code."
    },
    {
      "id": "INS-039",
      "content": "Distributed Discovery: Use AI agents as parallel interviewers to extract tacit knowledge from teams. Embed a MINILOOP.md file (a lightweight, single-file Loop-Flow installation) in a feature branch. Team members interact with the AI interviewer asynchronously, commit their session results, and the lead synthesizes findings. Advantages: no scheduling, less social pressure to 'know the answer', consistent protocol, captures verbatim quotes, scales across team.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "version-bump-0.6.0",
        "session": "2026-01-20-S7"
      },
      "tags": ["loop-flow-core", "distributed-discovery", "miniloop", "team-knowledge", "interviews"],
      "links": ["INS-019", "INS-025"],
      "created": "2026-01-20",
      "notes": "Documented in docs/DISTRIBUTED-DISCOVERY.md. MINILOOP is a 'probe' file — temporary, single-file Loop-Flow for feature branches."
    },
    {
      "id": "INS-040",
      "content": "Risk-focused code review: The value of AI-assisted PR review is risk identification, not style nitpicking. Categorize findings by deployment risk: CRITICAL (must fix before merge — breaks production, data loss, security), MEDIUM (suboptimal but functional, fix later OK), LOW (code style, nice-to-haves). Focus on: What could break in production? What's missing? What assumptions might be wrong?",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "version-bump-0.6.0",
        "session": "2026-01-20-S7"
      },
      "tags": ["loop-flow-core", "code-review", "pr-review", "risk-assessment"],
      "links": [],
      "created": "2026-01-20",
      "notes": "Documented in docs/PR-REVIEW-WORKFLOW.md. Practical workflow for AI-assisted PR reviews."
    },
    {
      "id": "INS-041",
      "content": "Skills provide reliable commands for starting and ending sessions. /loop-start reads .loop-flow/ state directly (no glob failures). /loop-end handles both graceful handoffs (updates backlog, progress, insights) and context emergencies (creates RESUME.md for seamless pickup). Skills follow the Agent Skills standard and work in Claude Code and OpenCode.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "skills-implementation",
        "session": "2026-01-20-S7"
      },
      "tags": ["loop-flow-core", "skills", "session-management", "reliability"],
      "links": ["INS-029", "INS-032"],
      "created": "2026-01-20",
      "notes": "Skills created in .claude/skills/ and .opencode/skills/. Templates in LOOP-FLOW-SETUP.md."
    },
    {
      "id": "INS-042",
      "content": "Claude Code and OpenCode have different skill/command models. In Claude Code, skills double as slash commands — users can type /skill-name directly. In OpenCode, skills are agent-only (invoked via skill() tool); for user slash commands, you need separate files in .opencode/commands/. Full cross-tool compatibility requires both: skills for agent invocation, commands for user invocation in OpenCode.",
      "type": "technical",
      "status": "discussed",
      "source": {
        "task": "ad-hoc-skills-audit",
        "session": "2026-01-20-S9"
      },
      "tags": ["skills", "commands", "opencode", "claude-code", "compatibility"],
      "links": ["INS-041", "INS-029"],
      "created": "2026-01-20",
      "notes": "Discovered by reading both tools' docs. OpenCode commands use .opencode/commands/*.md with frontmatter (description field). Claude Code commands merged into skills system."
    },
    {
      "id": "INS-043",
      "content": "End-loop must save state FIRST because it may be an emergency handoff. The user might be hitting context limits and need to bail out quickly. Do file writes (backlog.json, progress.txt, insights.json) before any summary or confirmation dialogue. Include an explicit checkpoint to verify saves actually happened.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "ad-hoc-end-loop-improvement",
        "session": "2026-01-20-S10"
      },
      "tags": ["loop-flow-core", "skills", "reliability", "emergency-handoff"],
      "links": ["INS-041", "INS-009"],
      "created": "2026-01-20",
      "notes": "Triggered by agent forgetting to save in Session 9. The SAVE-FIRST pattern prevents this."
    },
    {
      "id": "INS-044",
      "content": "Framework skills are a conceptual category distinct from user-defined skills. They ship with a methodology (like Loop-Flow) and are marked with `framework: <name>` in frontmatter. This keeps them in standard locations (.claude/skills/, .opencode/skills/) while clearly indicating origin. Framework skills are distributed via templates (LOOP-FLOW-SETUP.md) and should not be modified by users — fork instead. User-defined skills are project-specific and have no framework marker.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-022",
        "session": "2026-01-20-S11"
      },
      "tags": ["loop-flow-core", "skills", "architecture", "framework-skills"],
      "links": ["INS-029", "INS-041", "INS-042"],
      "created": "2026-01-20",
      "notes": "Distinguishes skills that come from frameworks (Loop-Flow, etc.) from project-specific user skills. Enables future tooling to differentiate them."
    },
    {
      "id": "INS-045",
      "content": "Cognitive tools for AI agents: Instead of CRUD operations, design tools as cognitive scaffolding. loop.orient (situational awareness), loop.remember (zero-friction capture), loop.connect (associative memory), loop.probe (structured questions), loop.handoff (session transitions). These match how agents actually think: needing context, capturing insights mid-flow, finding related knowledge, asking good questions, and preserving state across sessions.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-21-S15"
      },
      "tags": ["loop-flow-core", "mcp", "architecture", "cognitive-tools", "api-design"],
      "links": ["INS-022", "INS-008", "INS-043"],
      "created": "2026-01-21",
      "notes": "Core insight from Session 15. Traditional APIs are CRUD (create/read/update/delete). Cognitive APIs are scaffolding for how agents think. This reframes what an MCP server should provide."
    },
    {
      "id": "INS-046",
      "content": "Vibecode-then-explore: Instead of Learn → Design → Implement, try Vibecode → Explore → Understand. Build something concrete first (even if messy), then use it as a vehicle for learning. Abstract knowledge doesn't stick until you have something tangible to poke at. The working artifact becomes a teaching tool.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-21-S15"
      },
      "tags": ["loop-flow-core", "process", "learning", "vibecoding"],
      "links": ["INS-015", "INS-025", "INS-027"],
      "created": "2026-01-21",
      "notes": "Inverts the traditional learning flow. Session 15 validated this: we built a working MCP server first, THEN explored it. Understanding emerged from having something real to examine."
    },
    {
      "id": "INS-047",
      "content": "MCP servers can read file-based state directly without needing SQLite. The cognitive tools (loop.orient, etc.) read from .loop-flow/ files and provide value immediately. SQLite becomes optional for cross-repo aggregation, not a prerequisite. This simplifies the MVP path significantly.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-21-S15"
      },
      "tags": ["loop-flow-core", "mcp", "architecture", "simplification"],
      "links": ["INS-017", "INS-018"],
      "created": "2026-01-21",
      "notes": "Key simplification discovered in Session 15. Original plan required SQLite before MCP tools could work. New approach: MCP reads files directly, SQLite is a future enhancement for multi-repo queries."
    },
    {
      "id": "INS-048",
      "content": "Claude Code and OpenCode have different MCP config formats but both support stdio transport. Claude Code: ~/.claude.json or 'claude mcp add' command. OpenCode: opencode.json with 'mcp' key containing server definitions. Same MCP server binary works with both — just different registration.",
      "type": "technical",
      "status": "discussed",
      "source": {
        "task": "LF-001",
        "session": "2026-01-21-S15"
      },
      "tags": ["mcp", "claude-code", "opencode", "compatibility"],
      "links": ["INS-042"],
      "created": "2026-01-21",
      "notes": "Practical finding from Session 15. One MCP server implementation serves both tools. Config locations differ but the server code is shared."
    },
    {
      "id": "INS-049",
      "content": "claude-mem represents a different philosophy than LoopFlow: automatic capture vs intentional capture. claude-mem hooks into lifecycle events (PostToolUse, afterFileEdit, afterShellExecution) to capture EVERYTHING automatically, then uses AI to compress into summaries. LoopFlow relies on deliberate insight capture. Both have value: auto-capture ensures completeness, manual capture ensures meaning.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "claude-mem-analysis",
        "session": "2026-01-21-S16"
      },
      "tags": ["claude-mem", "architecture", "capture-philosophy", "comparison"],
      "links": ["INS-004", "INS-015"],
      "created": "2026-01-21",
      "notes": "Key philosophical difference discovered. claude-mem = 'remember everything, compress later'. LoopFlow = 'capture what matters, preserve theory'. The synthesis: dual capture - auto for completeness, manual for meaning."
    },
    {
      "id": "INS-050",
      "content": "Progressive disclosure is a token-efficiency pattern: never load full details upfront. claude-mem's 3-layer workflow: (1) search → compact index ~50-100 tokens/result, (2) timeline → chronological context, (3) get_observations → full details ~500-1000 tokens/result. Agent filters at each layer, achieving ~10x token savings. LoopFlow should adopt this pattern as knowledge accumulates.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "claude-mem-analysis",
        "session": "2026-01-21-S16"
      },
      "tags": ["claude-mem", "progressive-disclosure", "token-efficiency", "search"],
      "links": ["INS-024", "INS-007"],
      "created": "2026-01-21",
      "notes": "Critical for scaling. Current LoopFlow dumps full context. As insights accumulate, this becomes expensive. Progressive disclosure: show index first, let agent decide what to expand."
    },
    {
      "id": "INS-051",
      "content": "The distinction between observations and insights: Observations are raw events (tool calls, file edits, commands) - automatically captured, high volume, factual. Insights are synthesized knowledge (patterns, decisions, learnings) - manually captured, curated, meaningful. Observations answer 'what happened'. Insights answer 'why it matters'. Both are valuable; they serve different purposes.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "claude-mem-analysis",
        "session": "2026-01-21-S16"
      },
      "tags": ["claude-mem", "observations", "insights", "dual-capture", "loop-flow-core"],
      "links": ["INS-049", "INS-001"],
      "created": "2026-01-21",
      "notes": "This is the synthesis of claude-mem's approach and LoopFlow's philosophy. claude-mem calls them 'observations'. LoopFlow calls them 'insights'. They're complementary: observations are raw material, insights are refined knowledge."
    },
    {
      "id": "INS-052",
      "content": "Worker service architecture separates concerns: MCP server (lightweight, agent-facing, synchronous) vs Worker (heavy, async processing, web UI). claude-mem uses Bun worker on port 37777 for: AI summarization, embedding generation, queue processing, web viewer. This split enables async operations that would block the MCP server. Consider for LoopFlow if we add summarization or web UI.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "claude-mem-analysis",
        "session": "2026-01-21-S16"
      },
      "tags": ["claude-mem", "architecture", "worker-service", "async"],
      "links": ["INS-047"],
      "created": "2026-01-21",
      "notes": "LoopFlow MCP currently reads files synchronously. Works fine for now. Worker becomes valuable when we add: AI summarization, embeddings, web dashboard. Premature optimization if we don't need those features."
    },
    {
      "id": "INS-053",
      "content": "Timeline context complements associative search. loop_connect finds related insights by concept (associative). Timeline shows what was happening around a specific event (temporal). Use case: 'What was I working on when I made this decision?' helps reconstruct the reasoning narrative. Timeline + association = full context picture.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "claude-mem-analysis",
        "session": "2026-01-21-S16"
      },
      "tags": ["claude-mem", "timeline", "temporal-context", "search"],
      "links": ["INS-050"],
      "created": "2026-01-21",
      "notes": "Two dimensions of context: conceptual (what relates to this?) and temporal (what was happening when?). LoopFlow has the former via loop_connect. Timeline would add the latter."
    },
    {
      "id": "INS-054",
      "content": "Vibe-design: Start with a comprehensive best-effort design, then iterate. Like vibecode-then-explore but for architecture. Don't over-analyze upfront — draft the full design quickly, then poke holes. The draft becomes a vehicle for discovering what's wrong. This inverts traditional 'think deeply first' and instead uses the artifact to surface thinking.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "process", "design", "vibecoding"],
      "links": ["INS-046"],
      "created": "2026-01-21",
      "notes": "Applied in Session 18 for progressive disclosure design. Produced comprehensive spec in one pass, then refined via Q&A. The spec itself surfaced questions about SQLite, Ollama, DSPy."
    },
    {
      "id": "INS-055",
      "content": "Layered architecture for testability: MCP handlers → Services → Business Rules → Repositories → Storage. Business Rules are pure functions with no I/O — all domain logic lives here and is trivially testable. Services orchestrate and handle I/O. This seam pattern keeps the core logic isolated from infrastructure concerns.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "architecture", "testing", "pure-functions"],
      "links": ["INS-034", "INS-035"],
      "created": "2026-01-21",
      "notes": "Key architectural decision for progressive disclosure implementation. Scoring, summarization, filtering, migration transforms are all pure functions. Services compose them with I/O."
    },
    {
      "id": "INS-056",
      "content": "SQLite as source of truth with JSON views: Store data in SQLite for efficient queries, generate JSON files for human readability and git diffs. The JSON files become read-only views — still useful for inspection, but the database is authoritative. Best of both worlds.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "architecture", "sqlite", "json"],
      "links": ["INS-047"],
      "created": "2026-01-21",
      "notes": "Enables: efficient FTS5 search, proper indexes, atomic writes, schema migrations. Preserves: human-readable files, git-friendly diffs, backward compatibility with existing workflows."
    },
    {
      "id": "INS-057",
      "content": "Hybrid AI strategy: Heuristics as fast default, local LLM (Ollama) as optional enhancement, cloud AI as future possibility. The MCP server can detect if Ollama is running and use it opportunistically. This gives zero-cost operation by default with smart upgrades when available.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "architecture", "ai", "ollama"],
      "links": ["INS-024"],
      "created": "2026-01-21",
      "notes": "For summarization: heuristics (first sentence, truncation) are instant and free. Ollama with phi3 is local and cheap. Cloud AI is powerful but costly. Layer them: try heuristic, enhance with Ollama if available."
    },
    {
      "id": "INS-058",
      "content": "DSPy as programmatic prompt engineering: Instead of hand-crafting prompts, define typed signatures and let DSPy optimize them from examples. Aligns with 'developer has the reins' — you're engineering prompts, not vibing them. Challenge: DSPy is Python, LoopFlow is TypeScript. Options: subprocess, HTTP service, or port the concepts.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["dspy", "prompt-engineering", "ai", "future"],
      "links": ["INS-015", "INS-035"],
      "created": "2026-01-21",
      "notes": "High potential fit for LoopFlow. Signatures for: SummarizeInsight, ScoreRelevance, GenerateQuestions. Requires spike (LF-069) to evaluate integration patterns."
    },
    {
      "id": "INS-059",
      "content": "Persona-based AI architecture: Instead of traditional CRUD-style MCP tools, design cognitive tools as 'personas' the main agent can consult. Examples: Curator (keeper of insights, knows what's been learned), TaskMaster (workflow management, prioritization), Scholar (research + technical knowledge, builds knowledge bases), Contrarian (devil's advocate, finds flaws in reasoning), Council (orchestrates voting/consensus among personas). The main 'Codriver' agent reasons about which persona to consult for different needs.",
      "type": "architecture",
      "status": "unprocessed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "personas", "multi-agent", "architecture", "future"],
      "links": ["INS-045", "INS-060"],
      "created": "2026-01-21",
      "notes": "Shifts from 'tools as functions' to 'tools as collaborators'. Each persona encapsulates domain knowledge + judgment, not just data access. The Contrarian is particularly interesting — a built-in adversarial reviewer."
    },
    {
      "id": "INS-060",
      "content": "The Digital Clockwork Muse (Saunders & Gero, 2001): Computational model of creativity using multiple novelty-seeking agents in a social context. Key ideas: (1) Agents assess 'interestingness' of artifacts, (2) Agents communicate interesting discoveries to others, (3) Agents reward each other for finding interesting things. Creativity emerges from social dynamics between specialized agents, not from a single general agent. Searching for different degrees of novelty affects both artifacts produced and social organization.",
      "type": "domain",
      "status": "unprocessed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18",
        "external": "Saunders & Gero (2001) - The Digital Clockwork Muse: A Computational Model of Aesthetic Evolution"
      },
      "tags": ["creativity", "multi-agent", "novelty", "research", "digital-clockwork-muse"],
      "links": ["INS-059"],
      "created": "2026-01-21",
      "notes": "Academic foundation for persona-based architecture. The reward system and communication of discoveries maps well to LoopFlow's insight sharing. The 'interestingness' assessment maps to relevance scoring."
    },
    {
      "id": "INS-061",
      "content": "Fluid API paradigm: Instead of designing fixed APIs, design for creative reasoning by the main agent. The API becomes semantic — personas the agent can consult — rather than procedural. The agent reasons 'maybe the Curator can answer this' or 'let me ask the Contrarian'. This shifts from 'call the right function' to 'have a conversation with the right collaborator'. The API surface is smaller but the capability space is larger because the agent can creatively combine persona consultations.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "paradigm-shift", "fluid-api", "creative-reasoning", "personas"],
      "links": ["INS-059", "INS-060", "INS-062"],
      "created": "2026-01-21",
      "notes": "KEY INSIGHT: Traditional APIs constrain; semantic APIs enable. The main agent's creativity becomes the API's extensibility mechanism."
    },
    {
      "id": "INS-062",
      "content": "Use-case driven development with ad-hoc API: Development flows from discovered use cases, not pre-planned features. Use cases can be defined ad-hoc in markdown or plain description, then potentially crystallize into process insights. The loop: (1) User discovers a need, (2) Describes it in natural language, (3) Main agent reasons about how personas could address it, (4) If valuable, the pattern becomes a captured insight, (5) Insight informs future persona behavior. This is 'programming in English' that feeds back into the system's knowledge.",
      "type": "process",
      "status": "discussed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "paradigm-shift", "use-case-driven", "programming-in-english", "feedback-loop"],
      "links": ["INS-061", "INS-035", "INS-036"],
      "created": "2026-01-21",
      "notes": "BREAKTHROUGH: The API is not fixed — it evolves through use. Ad-hoc use cases become process insights which become system capabilities. This closes the loop between 'using LoopFlow' and 'developing LoopFlow'."
    },
    {
      "id": "INS-063",
      "content": "LoopFlow as self-improving system: The feedback loop from use-case discovery → ad-hoc description → insight capture → persona enhancement means LoopFlow improves itself through use. Each novel use case that gets captured as an insight expands the system's capability space. The developer isn't just using the tool — they're teaching it. This aligns with 'developer has the reins' but adds: developer also has the steering wheel for the tool's evolution.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "paradigm-shift", "self-improving", "feedback-loop", "meta"],
      "links": ["INS-062", "INS-061", "INS-002", "INS-015"],
      "created": "2026-01-21",
      "notes": "META-INSIGHT: LoopFlow becomes a theory-building system that builds theories about itself. The Naur framing (INS-002) applies recursively — LoopFlow preserves theory about how to preserve theory."
    },
    {
      "id": "INS-064",
      "content": "The creative agent as API extensibility: In traditional systems, extensibility comes from plugin architectures or configuration. In the persona paradigm, extensibility comes from the main agent's creative reasoning about how to use personas. New capabilities emerge not from code changes but from novel combinations of persona consultations. The system's capability space is bounded only by the agent's creativity in using it.",
      "type": "architecture",
      "status": "discussed",
      "source": {
        "task": "LF-049",
        "session": "2026-01-21-S18"
      },
      "tags": ["loop-flow-core", "paradigm-shift", "extensibility", "creative-reasoning", "emergence"],
      "links": ["INS-061", "INS-060"],
      "created": "2026-01-21",
      "notes": "This inverts the traditional relationship: instead of the API defining what's possible, the agent's creativity defines what's possible. The API provides building blocks; the agent provides the architecture."
    }
  ],
  "link_types": {
    "builds_on": "This insight extends or deepens another",
    "contradicts": "This insight challenges or refines another",
    "exemplifies": "This is a concrete example of an abstract insight",
    "synthesizes": "This insight was created by combining others"
  }
}
